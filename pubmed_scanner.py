import os
import sqlite3
import datetime
import time
import requests
from Bio import Entrez
import google.generativeai as genai

# --- è¨­å®šå€ ---

WEBHOOK_URL = os.getenv('WEBHOOK_URL')
NCBI_EMAIL = os.getenv('NCBI_EMAIL')
NCBI_API_KEY = os.getenv('NCBI_API_KEY')
GEMINI_API_KEY = os.getenv('GEMINI_API_KEY')

# æœå°‹é—œéµå­—
KEYWORDS = "Artificial Intelligence AND Epidemics"

# LLM æ¨¡å‹
MODEL_NAME = 'gemini-3-flash-preview' 

# --- åˆå§‹åŒ– ---
Entrez.email = NCBI_EMAIL
Entrez.api_key = NCBI_API_KEY
genai.configure(api_key=GEMINI_API_KEY)
model = genai.GenerativeModel(MODEL_NAME)

def init_db():
    """
    åˆå§‹åŒ– SQLite è³‡æ–™åº«
    ä¿®æ”¹é»ï¼šå¢åŠ æ¬„ä½æª¢æ¸¬ï¼Œè‹¥ä½¿ç”¨èˆŠç‰ˆ DB æœƒè‡ªå‹•å‡ç´š Schema
    """
    conn = sqlite3.connect('papers.db')
    c = conn.cursor()
    
    # å»ºç«‹è¡¨æ ¼ (å¦‚æœå®Œå…¨ä¸å­˜åœ¨)
    c.execute('''CREATE TABLE IF NOT EXISTS papers 
                 (pmid TEXT PRIMARY KEY, 
                  title TEXT, 
                  abstract TEXT, 
                  summary TEXT, 
                  processed_date TEXT)''')
    
    # --- è‡ªå‹•é·ç§»é‚è¼¯ (é‡å°èˆŠç‰ˆè³‡æ–™åº«) ---
    # æª¢æŸ¥ç›®å‰æœ‰å“ªäº›æ¬„ä½
    c.execute("PRAGMA table_info(papers)")
    existing_columns = [info[1] for info in c.fetchall()]
    
    # å¦‚æœç¼ºæ¬„ä½ï¼Œå°±å‹•æ…‹è£œä¸Š (Migration)
    new_columns = {
        'title': 'TEXT',
        'abstract': 'TEXT',
        'summary': 'TEXT',
        'processed_date': 'TEXT'
    }
    
    for col_name, col_type in new_columns.items():
        if col_name not in existing_columns:
            print(f"è³‡æ–™åº«å‡ç´šï¼šæ–°å¢æ¬„ä½ {col_name}")
            c.execute(f"ALTER TABLE papers ADD COLUMN {col_name} {col_type}")
            
    conn.commit()
    return conn

def search_pubmed(keywords):
    """æœå°‹éå» 1 å¤©å…§çš„è«–æ–‡ (é™åˆ¶ 10 ç¯‡æœ€æ–°)"""
    try:
        handle = Entrez.esearch(
            db="pubmed", 
            term=keywords, 
            reldate=1, 
            datetype="pdat", 
            retmax=10, 
            sort='date'
        )
        record = Entrez.read(handle)
        handle.close()
        return record["IdList"]
    except Exception as e:
        print(f"PubMed æœå°‹å¤±æ•—: {e}")
        return []

def fetch_details(pmid):
    """æ ¹æ“š PMID ç²å–æ¨™é¡Œã€æ‘˜è¦èˆ‡ DOI"""
    try:
        handle = Entrez.efetch(db="pubmed", id=pmid, retmode="xml")
        records = Entrez.read(handle)
        handle.close()
        
        if not records['PubmedArticle']:
            return None, None, None

        article = records['PubmedArticle'][0]['MedlineCitation']['Article']
        title = article['ArticleTitle']
        
        abstract_list = article.get('Abstract', {}).get('AbstractText', ["ç„¡æ‘˜è¦"])
        abstract = "".join([str(x) for x in abstract_list])
        
        doi = ""
        for id_obj in records['PubmedArticle'][0]['PubmedData']['ArticleIdList']:
            if id_obj.attributes.get('IdType') == 'doi':
                doi = str(id_obj)
                break
                
        return title, abstract, doi
    except Exception as e:
        print(f"ç²å–è«–æ–‡è©³æƒ…å¤±æ•— (PMID: {pmid}): {e}")
        return None, None, None

def summarize_ai(title, abstract):
    """ä½¿ç”¨ Gemini Flash é€²è¡Œç§‘æ™®æ‘˜è¦"""
    prompt = (
        f"ä½ æ˜¯ä¸€ä½å°ˆæ¥­çš„ç§‘æ™®ä½œå®¶ã€‚è«‹é–±è®€ä»¥ä¸‹é†«å­¸è«–æ–‡æ‘˜è¦ï¼Œ"
        f"ç”¨ç¹é«”ä¸­æ–‡å¯«ä¸€æ®µç´„ 100-150 å­—çš„ã€Œç§‘æ™®æ‘˜è¦ã€ã€‚"
        f"çµæ§‹è«‹åŒ…å«ï¼š1. èƒŒæ™¯èˆ‡å•é¡Œ 2. æ ¸å¿ƒç™¼ç¾ 3. æ„ç¾©ã€‚"
        f"è«‹ä½¿ç”¨æ¢åˆ—å¼æˆ–åˆ†æ®µï¼Œä½¿å…¶åœ¨èŠå¤©è»Ÿé«”ä¸­æ˜“æ–¼é–±è®€ã€‚\n\n"
        f"æ¨™é¡Œï¼š{title}\n"
        f"åŸå§‹æ‘˜è¦ï¼š{abstract}"
    )
    try:
        response = model.generate_content(prompt)
        return response.text
    except Exception as e:
        return f"æ‘˜è¦ç”Ÿæˆå¤±æ•—: {e}"

def send_chat_message(text):
    if not WEBHOOK_URL:
        return

    headers = {'Content-Type': 'application/json; charset=UTF-8'}
    data = {"text": text}
    
    try:
        requests.post(WEBHOOK_URL, json=data, headers=headers)
    except Exception as e:
        print(f"Webhook é€£ç·šéŒ¯èª¤: {e}")

def main():
    print(f"é–‹å§‹åŸ·è¡Œ - æ¨¡å‹: {MODEL_NAME} (è©³ç´°å­˜æª”ç‰ˆ)")
    conn = init_db()
    c = conn.cursor()
    
    pmids = search_pubmed(KEYWORDS)
    print(f"æ‰¾åˆ° {len(pmids)} ç¯‡ç›¸é—œè«–æ–‡")
    
    new_count = 0
    today_str = datetime.date.today().isoformat() # æ ¼å¼ï¼šYYYY-MM-DD
    
    for pmid in pmids:
        c.execute("SELECT pmid FROM papers WHERE pmid=?", (pmid,))
        if c.fetchone():
            continue 
            
        print(f"è™•ç†æ–°è«–æ–‡: {pmid}")
        title, abstract, doi = fetch_details(pmid)
        
        if title and abstract:
            summary = summarize_ai(title, abstract)
            link = f"https://doi.org/{doi}" if doi else f"https://pubmed.ncbi.nlm.nih.gov/{pmid}/"
            
            # 1. ç™¼é€é€šçŸ¥
            message = (
                f"ğŸ“„ *{title}*\n"
                f"{'-'*20}\n"
                f"{summary}\n\n"
                f"ğŸ”— <{link}|é»æ“Šé–±è®€åŸæ–‡>" 
            )
            send_chat_message(message)
            new_count += 1
            
            # 2. å­˜å…¥è©³ç´°è³‡æ–™ (ä¿®æ”¹é»)
            # è³‡æ–™çµæ§‹ï¼š(pmid, title, abstract, summary, processed_date)
            try:
                c.execute(
                    "INSERT INTO papers (pmid, title, abstract, summary, processed_date) VALUES (?, ?, ?, ?, ?)", 
                    (pmid, title, abstract, summary, today_str)
                )
                conn.commit()
            except sqlite3.OperationalError as e:
                # é é˜²æ€§çš„éŒ¯èª¤æ•æ‰ï¼Œé›–ç„¶ init_db å·²ç¶“è™•ç†éé·ç§»
                print(f"è³‡æ–™åº«å¯«å…¥éŒ¯èª¤: {e}")

            time.sleep(1) 
    
    if new_count > 0:
        send_chat_message(f"âœ… ä»Šæ—¥æ›´æ–°å®Œç•¢ï¼Œå…±æ¨é€ {new_count} ç¯‡æ–°è«–æ–‡ã€‚")
    else:
        print("ä»Šæ—¥ç„¡æ–°è«–æ–‡ï¼Œæœªç™¼é€è¨Šæ¯ã€‚")
    
    conn.close()

if __name__ == "__main__":
    main()
